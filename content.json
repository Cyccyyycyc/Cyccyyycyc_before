{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2022-10-20T06:51:59.327Z","updated":"2022-10-20T06:51:59.327Z","comments":false,"path":"/404.html","permalink":"http://example.com/404.html","excerpt":"","text":""},{"title":"关于","date":"2022-10-20T06:51:59.330Z","updated":"2022-10-20T06:51:59.330Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2022-10-20T06:51:59.331Z","updated":"2022-10-20T06:51:59.331Z","comments":false,"path":"books/index.html","permalink":"http://example.com/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-10-20T06:51:59.334Z","updated":"2022-10-20T06:51:59.334Z","comments":false,"path":"repository/index.html","permalink":"http://example.com/repository/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2022-10-20T06:51:59.333Z","updated":"2022-10-20T06:51:59.333Z","comments":true,"path":"links/index.html","permalink":"http://example.com/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-10-20T06:51:59.332Z","updated":"2022-10-20T06:51:59.332Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-10-20T06:51:59.335Z","updated":"2022-10-20T06:51:59.335Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"The Transfer-based Black-box Attack Method by 韦星星","slug":"The-Transfer-based-Black-box-Attack-Method-by韦星星","date":"2022-10-19T15:57:49.000Z","updated":"2022-10-20T07:52:45.817Z","comments":true,"path":"2022/10/19/The-Transfer-based-Black-box-Attack-Method-by韦星星/","link":"","permalink":"http://example.com/2022/10/19/The-Transfer-based-Black-box-Attack-Method-by%E9%9F%A6%E6%98%9F%E6%98%9F/","excerpt":"","text":"观后感 Source The 4th Lecture 基于Spatial Momentum的迁移性增强方法FGSM : Fast Gradient Sign Method白盒场景下，用符号获得梯度方向，在原图增加噪声（对抗扰动）来生成对抗样本，是一种单步迭代攻击。 I-FGSM : Iterative Fast Gradient Sign Method多步迭代攻击，拟合效果更好了，但是迁移性不太好（可以从overfit角度直观理解） 时序累加角度：时间域变换MI-FGSM时序上的梯度累加：当前梯度+过去梯度 NI-FGSM数据增广角度：空间域变换DII-FGSM : Diverse Inputs从数据增强角度，对输入数据有概率p进行随机大小的resize TI-FGSM : Translation invariant - FGSM从数据增强角度，考虑像素点的领域（高斯）来生成对抗样本。 时空累加角度R-DIMI-FGSM考虑梯度在空间上的累加，比较范围更广 图像检测对抗样本的生成现有方法问题现有攻击方法常常针对Fast-rcnn，攻击模型中的的分类模块（常常表征高级特征），而有些图像检测模型如yolo模型中无分类模块，则导致迁移性差。 迁移性差，在一个模型训练生成的对抗样本往往无法成功攻击另一个模型。 时间复杂度高 改进改进描述一种想法是对抗样本迁移和模型之间的共性相关。要想增强迁移能力，则应该从模型间的共性切入。 传统方法是攻击Fast-rcnn模型中的分类模块，而有些模型中不存在分类模块，则分类模块显然不是模型的共同子架构。 因此，提出基于base network的对抗样本生成，取Fast-rcnn模型中一些普遍应用的架构（如VGG、ResNet一些经典架构…），用attention机制来定位特征层的目标机制，增加feature loss，从中间特征层入手破坏物体特征层的特征（原来是直接攻击模型更后面更高级的分类模块），获得更高的迁移性。 Q1 ：底层特征更共性？这时候可能有人会提出一个问题，既然攻击迁移性往往和模型之间的共同点高度相关，那为什么不选取破坏更加具有共性的底层特征来获得更大的迁移性呢？回答是这样对图片的破坏较大，会导致对抗样本和原图的距离较远，选择在中间特征层攻击是对图片质量（和原图的相似度）和迁移性的权衡结果。 进一步解释，神经网络往往是一个放大的过程，在底层添加微小噪声，经过网络不断放大，最终和原图便相去甚远。 Q&amp;AQ1：可以从什么角度切入提高迁移性? 从梯度出发，找到一个更泛化的梯度计算的方法 从模型架构共性出发。现在的模型架构趋于模块化，更容易找到共性，提高迁移性。 （笔者目前个人认为）从模型拟合数据分布的角度出发。不同模型学到的知识不同，有的模型注重纹理有的注重轮廓。 Q2 ：无法被迁移攻击的模型？ 从模型架构共性出发：黑盒场景下，如果一个模型无法被迁移攻击，那么说明本地模型和目标模型相似度极低。这不太符合现实应用。不过脉冲神经网络或许是一个角度。 从模型拟合数据分布角度出发：往往经过对抗训练的模型会具有更高的鲁棒性，相同架构下往往会更难以被对抗攻击，这表明模型拟合出了一个不一样的分布，这个分布含有更多的知识。（有点像“吃一堑长一智”，模型之前见识过了对抗攻击，便学会了如何应对） Q3 ：语义角度的迁移攻击？现有方法往往修改图像亮度、锐度、饱和度等属性（对抗属性）来生成对抗样本。可以进行扩展，尝试修改一些视觉友好的语义属性（比如颜色）来生成对抗样本，思考并探索：哪种属性更易于迁移？ Q4 ：如何寻找共性？ 从data的特征空间变换角度，可以寻找不同模型之间的一致性 从降维解构角度，可以实现降低搜索维度，在低维空间中搜索降低时间复杂度，在高维空间中攻击获得好的攻击效果。 Q5 ：迁移性的理论相关？目前理论尚待完善。 关于可迁移性的度量，由于迁移并不独立存在，一定是从一个模型到另一个模型，所以目前也无统一度量方法。 Q6 ：可证明的迁移攻击的防御由于目前迁移攻击的发展空间巨大（效果很差成功率很低），所以没有相关的防御。一般经过对抗训练就能很好地防御了。","categories":[{"name":"AISP","slug":"AISP","permalink":"http://example.com/categories/AISP/"}],"tags":[{"name":"对抗样本","slug":"对抗样本","permalink":"http://example.com/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/"}]},{"title":"Deepfake by 吕思伟","slug":"Deepfake-by吕思伟","date":"2022-10-18T13:55:02.000Z","updated":"2022-10-20T07:50:07.825Z","comments":true,"path":"2022/10/18/Deepfake-by吕思伟/","link":"","permalink":"http://example.com/2022/10/18/Deepfake-by%E5%90%95%E6%80%9D%E4%BC%9F/","excerpt":"","text":"观后感 Source The 3td Lecture DEEP FAKEBackground 硬件近年来发展迅速，甚至超过了摩尔定律描述的速度。 互联网用户多，数据体量庞大，且传播较快较广泛。 AI发展迅速（其实是被大数据和高效的计算资源推着发展的） ApplicationGAN-based Image生成的fake_images有如下目标： 质量高，有逼真的特征细节纹理 种类多 DNN-based Speech VC (voice conversion)：可以理解为风格转换，A的内容＋B的风格 TTS (Text to Speech) AE-based Video理解为逐帧进行替换（风格转换） Decoder 分离identity and message，Encode进行一个重新添加。 问题：耗费较多训练资源，目前还需要比较多的人为调整，而调整操作必然留下痕迹，这也利于检测。 ImpactPositive 电影高难度动作、或者一些场景都可以进行生成 游戏、远程教育可以通过生成提高交互性 利于数字匿名化，隐藏个人的identity，可用于个人隐私保护 生成更具多样性的数据集 Negative(main) 制造假象，混淆视听，误导大众做出错误决策 降低公众对媒体的信任感，俗称一颗老鼠屎坏了一锅粥 信息量变大了，含金量并没有提高，信息流变得更为复杂。 Detection虚假信息其实一直都存在，只是随着AI的发展，虚假信息流增强，更难以分辨且威胁性更大，由此Deep-Fake Detection愈发重要。 下图为吕思伟教授在讲座中给出的DeepFake Detection分类 首先明确DeepFake检测是一个二分类问题。 其次可分为Single-modality 和 Multi-modality。 目前主流是Single-modality –&gt; Frame-based –&gt; Data-driven的检测手段。 Cue可以理解为Feature： Signal cues：不关心内容，只关心数据本身构成。如Post-processing方法，即为检测生成fake_images后贴到视频里的后处理痕迹，鉴定是否为真。 Semantic cues：关心数据内容本身是否符合规律。如人脸各个组成的朝向是否正确，如眨眼频率。（个人感觉听起来可延展性较弱，貌似只能针对特定数据特定分布，而且开源后攻击者就可以注意到这个规律，生成符合特定规律的图像就可以骗过检测模型了） 总体感觉，没有一个普适性的、统一的、可延展的完善的检测方法，较为零碎。 Challenge 可解释性：随着Deep-Fake的负面影响越来越严重，除了需要检测出”鉴定为假“的结果，在实际应用中，往往不能单纯依靠机器判别，还需要给出假的理由。 目前检测方法从不同角度切入，种类很多，但可扩展性不强，缺乏一个统一的检测方法。攻击者可以很容易针对专门检测方法进行调整，绕过检测防御。 很多检测方法误判率较高。实际应用中容易影响用户体验感。 目前的检测手段实际上是一种事后的被动防御。现在很多人都有一致的想法，利用后门去破坏Deep-Fake的生成，进行主动防御。 Future 生成范围逐渐扩展。不再局限于人脸，逐渐生成四肢、全身… 共同生成音效＋视频帧，更加逼真 逐步减少对数据的依赖。比如由单张图片生成动态的视频，由低维构建高维场景。","categories":[{"name":"AISP","slug":"AISP","permalink":"http://example.com/categories/AISP/"}],"tags":[{"name":"DeepFake","slug":"DeepFake","permalink":"http://example.com/tags/DeepFake/"}]},{"title":"深度学习反脆弱技术的攻防和测评By刘祥龙","slug":"深度学习反脆弱技术的攻防和测评By刘祥龙","date":"2022-10-18T11:55:09.000Z","updated":"2022-10-20T07:52:53.894Z","comments":true,"path":"2022/10/18/深度学习反脆弱技术的攻防和测评By刘祥龙/","link":"","permalink":"http://example.com/2022/10/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%8D%E8%84%86%E5%BC%B1%E6%8A%80%E6%9C%AF%E7%9A%84%E6%94%BB%E9%98%B2%E5%92%8C%E6%B5%8B%E8%AF%84By%E5%88%98%E7%A5%A5%E9%BE%99/","excerpt":"","text":"Source: 论坛网站The 2nd Lecture 引入安全挑战非人为刻意引发网络安全，公共安全（安检、自动驾驶），国防安全（侦察、遥感监测）等 人为刻意构造的全新类型攻击对抗样本、噪音污染、数据投毒、数据伪造、后门攻击… 对抗样本特点一类被恶意设计来攻击AI模型的样本 与真实样本的差异不易感知 可以导致模型进行错误的判断 “脆弱性在深度学习中具有普遍性”（Nature 2019）本次主要从对抗样本角度出发关注深度学习的脆弱性。 数字世界中的对抗样本特点 微小扰动，不易觉察 语义不变而欺骗模型 攻击分类 黑盒攻击 白盒攻击 FGSM attack:2014,基于梯度的攻击攻击假设：白盒，可以获得模型反向传播的梯度符号 特点1.fast2.sign C&amp;W attack:2017,基于优化的攻击攻击假设：白盒，攻击者需要获得模型数据 数学理解D：distanceC：classificationf: 目标函数。当且仅当 f(x+δ)≤0时, C(x+δ)=t 函数连续：因为要进行优化，所以目标函数需要是光滑连续有梯度的。slow：因为涉及多步优化计算w，所以速度相对较慢。 PBBA:2017,基于迁移的攻击 攻击假设：黑盒 对代理模型的攻击迁移到其它模型 AdvGAN:2018,基于模型的攻击攻击假设：白盒生成，需要获得受害者模型数据来计算adv-L 其它任务Video Analysis视频逐帧攻击 Speech RecognitionNatural Language Processing自然语言处理领域的对抗样本：对于人类，语序不影响阅读，而文本字母顺序的调换会让模型输出错误的结果。 Reinforcement Learning强化学习领域对抗样本的运用实际上是对策略的攻击一种理解是模型本身不够完善，没有学习到如何应对这个策略 防御物理世界中的对抗样本物理世界对抗样本：改造物理实体以进行攻击受限于：感知器质量、光照强度、远近距离…与数字世界对抗样本相比，物理世界对抗样本具有黑盒特性，更复杂，危险性更大 根据数字世界和物理世界的差异，给出对抗样本泛化定义：1.对于人类，视觉上具备友好性 For human, it disguises as a normal example.2.对于模型具有攻击性，可以欺骗模型 For models, it misleads the model predictions 反脆弱技术体系脆弱性原理从关键决策路径动态地来看：关键攻击路径刻画了从输入端到决策输出端错误输出的传播路径，这是对模型泛化应用影响最大的路径。表明神经网络中存在脆弱单元，脆弱路径。 从注意力机制来看：模式识别存在一定偏好，可能对特定的特征（如纹理）有一定偏好（理解为容易激活） 脆弱性检测深度学习网络的对抗鲁棒性和自然噪音鲁棒性往往呈现正相关。提高对抗鲁棒性利于整体鲁棒性的优化，这需要完备数据集的支撑。 问题：人工智能要想获得广泛使用，成为基础设施，就要有可靠性的保证。挑战：建立完善的评估指标、技术规范和工具集，去测试其模型的可靠性。 反脆弱加固数据端过滤有害数据，但没有优化模型本身的反脆弱能力。 1.污染检测对于数据进行domain迁移，数据增强，提高模型泛化能力 2.污染抑制增加防御补丁 3.污染抑制利用W-Distance来进行数据增强，提高模型泛化能力 模型端：提高鲁棒性1.训练加固模型单元增强：在中间层注入多样化的对抗噪音，提高鲁棒性，使其学习到更多的语义信息 2.结构优化：抑制脆弱路径：剪枝，压缩，稀疏化，量化，一定程度上可以抑制噪音中心加权归一化BN进行神经网络模型数据分布整合，提高模型分布的稳定性和收敛性，改善了曲率 Q&amp;A 如何平衡模型的精确性和鲁棒性？模型的精确性和鲁棒性使多因素共同作用下的结果，应该全面分析不同因素作用，综合考量设计优化目标 一种设想：大网络下的特定子网络结构具有鲁棒性","categories":[{"name":"AISP","slug":"AISP","permalink":"http://example.com/categories/AISP/"}],"tags":[{"name":"对抗样本","slug":"对抗样本","permalink":"http://example.com/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/"}]},{"title":"数字图像处理","slug":"数字图像处理","date":"2022-10-18T11:32:23.000Z","updated":"2022-10-20T08:06:23.632Z","comments":true,"path":"2022/10/18/数字图像处理/","link":"","permalink":"http://example.com/2022/10/18/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/","excerpt":"","text":"图像基础图片表示二值图只有2种取值 灰度图unit8 8位灰度图（0~255） 二维矩阵（一个通道） 彩色图三维矩阵（RGB三个通道） 真彩色 通道的分离和合并12345img_bgr = cv.imread(img_path)# 通道分离b, g, r = cv.split(img_bgr)# 通道合并img_rgb = cv.merge([r, g, b]) 彩色图转换成灰度图1234567# 三通道按权值加权 0.299 0.587 0.114gray1 = 0.299 * r + 0.587 *g + 0.114 *b# dtype = uint8gray2 = np.uint8(gray1)gray3 = gray1.astype(np.uint8)gray4 = cv.cvtColor(img_bgr, cv.COLOR_BGR2GRAY) 图像二值化123456thresh = 125gray4[gray4 &gt; thresh] = 255gray4[gray4 &lt;= thresh] = 0# gray4 已经被二值化ignore, img_bin = cv.threshold(gray_uint8_img, th1, th2, cv.THRESH_BINARY) 图像运算图像相加混合图像、添加噪声 12345# dtype = float64img_add1 = cv.add(img1*0.5, img2*0.5)# dtype = uint8img_add2 = cv.addWeighted(img1, alpha, img2, beta, gamma) 图像相减消除背景、差影法（比较差异，运动跟踪） 1img_sub = cv.subtract(img1, img2) 图像相乘掩膜mask 1img = cv.multiply(img1, img2) 图像相除校正设备、比较差异 1img = cv.divide(img1, img2) 图像变换线性变换$$s=b+kr$$ 1img = cv.convertScaleAbs(img, alpha=1, beta=0) 非线性变换$$s=a+\\frac{ln(r+1)}{blnc}$$ Gamma变换$$s=cr^y$$ y越大图像越亮 12img = img / 255img = np.power(img, y) * 255 图像处理裁剪12345# numpyimg = cv.imread(img_path)# h * w * c# y * x *cimg = img[20:100, 100:200, :] 放缩123# OpenCv# (x, y)=(w, h)=(500,400)img = cv.resize(img, (500, 400)) 平移仿射变换 123# 坐标的映射矩阵MM = np.array([...], dtype=np.float32)cv.warpAffine(img, M, dsize) 错切变换12M = np.array([...], dtype=np.float32)img = cv.warpAffine(img, M, dsize) 镜像变换123456789101112# 矩阵M = np.array([...], dtype=np.float32)img = cv.warpAffine(img, M, dsize)# 垂直镜像cv.flip(img, 0)# 水平镜像cv.flip(img, 1)# 同时进行cv.flit(img, -1) 旋转变换123456789101112# 旋转矩阵M = np.array([...], dtype=np.float32)img = cv.warpAffine(img, M, dsize)# M = cv.getRotationMatrix2D(center, angle, scale)h, w, c = img.shape# center = (x, y)M = cv.getRotationMatrix2D((w//2, h//2), 45)img = cv.warpAffine(img, M, dsize)# 顺时针逆时针旋转90°img_rotate = cv.rotate(img, cv.ROTATE_90_CLOCKWISE) 透视变换12M = cv.getPerspectiveTransform(src, dst)img = cv.warpPerspective(img, M, dsize) 小总结像素值没变，像素位置变了。所以实际上计算了一个坐标变换的矩阵M。 最近邻插值逆向思维：小图插值变大图 —&gt; 大图变小图 1img1 = cv.resize(img, dsize, interpolation=cv.INTER_NEAREST) 双线性插值考虑邻近的像素点，按照权值计算。 1img1 = cv.resize(img, dsize, interpolation=cv.INTER_LINEAR_EXACT) 图像模糊卷积1img = cv.filter2D(img, -1, kernel) 均值模糊123cv.blur(img, (5,5))cv.boxFilter(img, -1, (5,5)) 中值滤波1cv.medianBlur(img, 3) # 奇数 高斯模糊1234# sigma 方差# 方差小则copy原图# 方差大则和均值滤波差不多cv.GaussianBlur(img, (5,5), sigmaX) 双边滤波一般模糊会丢失边缘信息，而双边滤波可以保留边缘高频信息，平滑颜色相近的地方。 需要一直更新卷积核的值： 距离越远，加权值越小 颜色差异越大，加权值越小 缺点：对高频噪声无滤波效果 1cv.bilateralFilter(img, -1, sigmaColor=50, sigmaSpace=3) 图像边缘……","categories":[{"name":"cv","slug":"cv","permalink":"http://example.com/categories/cv/"}],"tags":[]}],"categories":[{"name":"AISP","slug":"AISP","permalink":"http://example.com/categories/AISP/"},{"name":"cv","slug":"cv","permalink":"http://example.com/categories/cv/"}],"tags":[{"name":"对抗样本","slug":"对抗样本","permalink":"http://example.com/tags/%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC/"},{"name":"DeepFake","slug":"DeepFake","permalink":"http://example.com/tags/DeepFake/"}]}